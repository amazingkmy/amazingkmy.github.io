---
title: InstructGPT 논문 리뷰 - 1 
author: amazingkmy
day: 2023.06.11
---

# InstructGPT 논문 리뷰 - 1
블로그의 제목처럼 저는 머리가 좋은(?) 사람은 아닌거 같아요. 최근이라고 하기에는 조금 늦은 감이 있는 Open AI에서 나온 논문을 보려고 합니다ㅎ
최근, 생성형 AI라는 단어가 유명해지고 주목받고 있는 시점에서 이 논문이 크게 기여를 하지 않았나 싶습니다.
알파고 이후에 나온 기술의 발전 중의 최고의 발전이라고 생각하는데요. 논문 리뷰는 라이트하게 하는 만큼 많은 지적 포인트들이 있을텐데
이런 부분들은 과감하게 연락주시면 감사하겠습니다.

---

## InstructGPT 논문 제목
논문 제목은 **Training language models to follow instructions with human feedback** 입니다. 논문 제목에서 GPT의 핵심적인 내용들을 확인해보실 수 있는데요. AI 모델임에도 불구하고 follow instructions with Human Feedback이 들어가게 되었죠? 이 내용으로 미루어보아 AI 모델에 사람이 개입하고, 사람을 따르도록 학습하게 됨을 어느정도 유추해볼 수 있게 됩니다.

---
## InstructGPT 초록
보통 논문은 초록에서 무엇을 말하고자 하는지 적혀있습니다. 논문의 핵심적인 내용만 알고 싶다면 초록, 실험결과, 결론만 봐도 어느정도 파악할 수 있는 내용이지요.
이 논문에서는 초록에서 다음과 같은 이야기를 하고 있습니다.

* 모델 사이즈가 크다고 해서 사람의 본질적인 의도를 파악하는 것은 아니다.
* 이 논문에서는 모델에 사람의 검토(피드백)를 통해 미세 조정을 하였더니 광범위하게 사람의 의도에 맞는 결과가 나오기 시작했다.
* GPT-3에 수집된 데이터 셋을 이용하여 미세조정을 하고, 모델 결과에 랭킹을 매겨 강화학습으로 모델을 한번 더 학습합니다.
* 이 모델의 이름은 InstructGPT라고 부르며, GPT-3보다 100배 낮은 파라메타에서도 사용자의 의도에 적합한 결과가 나왔습니다.

정리하면, 지금까지의 GPT 학습은 많은 데이터양과 많은 네트워크로 알아서 학습하도록 했었다면, InstructGPT는 학습하는 과정에서 사람이 개입해서 사람의 의도에 알맞은 결과를 내보내도록 학습하는 것이지요.
AI모델에게 학습하는 과정을 알아서 하라고 했다면, 지금은 학습은 수행하되 큰 틀은 인간이 교육해주겠다는 의미로 이해하시면 좋을 것 같습니다.

---
## InstructGPT 서론
NLP(자연어처리)에서 LLM(Large Language Models)는 많은 혁신을 가져다 주었지만, 이상한 이야기를 만들어내는 등 사용자가 원하지 않는 방향으로 문장을 생성해내는 좋지 않은 결과를 보여주고 있는데요. 아무래도 LLM이 웹페이지에 있는 많은 데이터들을 학습하면서 다음 토큰(쉽게 말하면 단어)을 학습하는데 집중했던 것이 원인이 아닐까 생각하게 되었다고 하는데요.
그렇다면, 학습함에 있어서 사용자의 의도에 따라 작동하도록 언어모델을 학습하면 좋은 모델이겠죠? 여기에서 사용자의 의도의 핵심은 Hallucination, biased, harmful 한 내용이 아닌 것을 의미하죠.
이런 언어모델 조정을 Open AI에서는 RLHF(Reinforcement Learning for Human Feedback)를 이용해서 GPT-3에 미세조정을 하기로 결정하였다. 여기에서 RLHF는 2017년 2020년에 나온 개념이였네요.
미세조정을 하는 과정은 다음과 같습니다. 


1. 한 모델을 이용해서 사람들을(논문에서는 40명을 두었다고 하네요) 모아서 모델에 학습 시킬 데이터를 구축하여 미세조정을 한다.
2. 미세조정을 한 모델들을 가지고 사람들이 데이터를 주고 생성하도록 한 후에, 여러개의 결과들을 가지고 순서를 매겨서 어떤 것이 가장 잘 만든 데이터인지 순위를 매기는 작업을 한다.
3. 이런 작업들을 이용해 Ranking Model을 학습한다.
4. 학습된 RM 모델의 Reward Function로 1번에서 학습한 모델을 학습한다. 이 떄 사용한 알고리즘은 PPO 알고리즘 이다

이렇게 진행하였더니, GPT-3 모델보다 사람에 가까운 결과 값을 보였다고 하네요.

이후는 나중에 작성하겠습니다..!!